{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z-IZalY8OID"
      },
      "source": [
        "# From Pixels to Patterns: Unsupervised Clustering of Handwritten Digits\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates unsupervised clustering of handwritten digit images using K-means clustering, following dimensionality reduction with Principal Component Analysis (PCA). The Digits dataset contains 1,797 grayscale images of digits (0–9), each represented as a 64-dimensional vector. To improve interpretability and visualization, we first reduce the dimensionality to 2 using PCA.\n",
        "\n",
        "While the handwritten digits dataset is commonly used for supervised classification tasks and algorithm benchmarking, in this homework, we assume that the digit labels are unknown. Our goal is to group the images into clusters purely based on their pixel features using unsupervised learning techniques.\n",
        "\n",
        "We explore two methods to determine the optimal number of clusters: the Elbow Method and the Silhouette Score. After selecting the optimal `k`, K-means is applied and the results are visualized in the reduced 2D PCA space.\n",
        "\n",
        "## Dataset\n",
        "The dataset is loaded from `sklearn.datasets.load_digits()`. Each image is represented by 64 features (8x8 pixels), with values ranging from 0 to 16. PCA reduces the data to 2 dimensions for visualization.\n",
        "\n",
        "## Task\n",
        "Write a Python script in this notebook that performs the following steps:\n",
        "1. **Load the Dataset**: Load the Digits dataset from `scikit-learn`.\n",
        "2. **Preprocessing with PCA**: Apply PCA to reduce the 64-dimensional data to 2 dimensions for clustering and visualization.\n",
        "3. **Determine Optimal Clusters**: Use the Elbow Method and the Silhouette Score to find the optimal number of clusters (`k`) for K-means clustering.\n",
        "4. **Apply K-means Clustering**: Fit a K-means model to the 2D data using the optimal `k` you determined. Assign each digit to a cluster.\n",
        "5. **Visualize the Results**: First apply PCA to reduce the dimantionality of samples from 64 to 2 dimentions. Next, create a scatter plot of the 2D data, with points colored by cluster and centroids marked. Label axes as PCA Component 1 and PCA Component 2.\n",
        "\n",
        "## Requirements\n",
        "- Use Python with the libraries: `pandas`, `numpy`, `matplotlib`, `scikit-learn`.\n",
        "- Include comments in your code to explain each step.\n",
        "- Handle potential errors (e.g., missing data) with appropriate checks or assumptions.\n",
        "- Submit your completed notebook as a `.ipynb` file.\n",
        "\n",
        "## Starter Code\n",
        "Below is starter code to help you begin. Complete the missing parts to finish the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwJ6x4NP8OIF"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data  # 64-dimensional data\n",
        "print(\"Dataset loaded successfully!\")\n",
        "# YOUR CODE HERE: Print the data shape\n",
        "\n",
        "\n",
        "# Step 2: Determine optimal number of clusters using the Elbow Method\n",
        "wcss = []  # Within-Cluster Sum of Squares\n",
        "for i in range(1, 16):  # Try k from 1 to 15\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    # YOUR CODE HERE: Fit the model to X\n",
        "    wcss.append(kmeans.inertia_)  # Record the WCSS\n",
        "\n",
        "# YOUR CODE HERE: Plot the Elbow Curve (X_axis: number of clusters, and y_axis: WCSS), fig size: 8 by 5\n",
        "\n",
        "'''\n",
        "In this elbow plot, the curve gradually decreases without a very sharp\n",
        "\"elbow,\" making it a bit tricky to identify the optimal number of clusters.\n",
        "In such situations, another method like the Silhouette Score might be more\n",
        "appropriate.\n",
        "'''"
      ],
      "metadata": {
        "id": "objT2U4tZVq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The Silhouette Score is a metric used to evaluate the quality of clustering\n",
        "results by measuring how well each data point fits within its assigned cluster\n",
        "compared to other clusters. It ranges from -1 to 1, where a higher value\n",
        "indicates that the data points are well-matched to their own cluster and poorly\n",
        "matched to neighboring clusters. After using the Elbow Method—which helps us\n",
        "estimate the optimal number of clusters by observing the point where adding more\n",
        "clusters doesn’t significantly reduce the within-cluster sum of squares\n",
        "(WCSS)—we use the Silhouette Score as a complementary method to validate our\n",
        "choice. While the Elbow Method relies on visual interpretation and can be\n",
        "subjective, the Silhouette Score provides a more objective, data-driven\n",
        "assessment of cluster separation and cohesion. This two-step approach gives us\n",
        "greater confidence in selecting the best number of clusters for our dataset.\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Step 3: Compute silhouette scores for different values of k\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 16)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    labels = kmeans.fit_predict(X)\n",
        "    score = silhouette_score(X, labels)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "# Plot the silhouette scores (X_axis: number of clusters, and y_axis: silhouette_scores), fig size: 8 by 5\n",
        "\n",
        "# Print the best k\n",
        "optimal_k = # YOUR CODE HERE: select the number of clusters corresponds to the maximum silhouette_scores. Hint: Use \"np.argmax\" command\n",
        "\n",
        "print(f\"The optimal number of clusters based on silhouette score is: {optimal_k}\")\n",
        "print(f\"We observe that the number of clusters determined by the Silhouette score, i.e., {optimal_k}, is quite close to the actual number of clusters, which is 10.\")"
      ],
      "metadata": {
        "id": "v2BKhoMyad6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: 2D Projection via PCA\n",
        "# Principal Component Analysis (PCA) is applied to reduce the dimensionality of\n",
        "# the samples from 64 to 2, facilitating the visualization of clusters.\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = # YOUR CODE HERE: Fit and transform the data with PCA\n",
        "\n",
        "# Check the new shape\n",
        "print(f\"PCA-transformed data shape: {X_pca.shape}\")  # Should be (1797, 2)\n",
        "\n",
        "# Check for missing values\n",
        "if np.any(np.isnan(X_pca)):\n",
        "    print(\"Warning: PCA-transformed data contains missing values. Consider handling them.\")\n",
        "else:\n",
        "    print(\"No missing values in PCA-transformed data.\")"
      ],
      "metadata": {
        "id": "YXtt_mUtfZCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGmBXjxR8OIG"
      },
      "outputs": [],
      "source": [
        "# Step 5: Apply K-means clustering with optimal k\n",
        "# Initialize and fit KMeans with your chosen optimal_k\n",
        "kmeans = # YOUR CODE HERE: Fill this in\n",
        "cluster_labels = # YOUR CODE HERE: Fit and predict cluster labels using X_pca\n",
        "\n",
        "# Get cluster centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Step 5: Visualize the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(optimal_k):\n",
        "    plt.scatter(X_pca[cluster_labels == i, 0], X_pca[cluster_labels == i, 1], s=50, label=f'Cluster {i+1}')\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], s=200, c='black', marker='x', label='Centroids')\n",
        "plt.title('Digits Clusters in PCA Space')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# YOUR CODE HERE: Save the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "For visual comparison, we plot the clusters using the actual number of clusters (k = 10).\n",
        "'''\n",
        "# Step 6: Apply K-Means clustering with the actual number of clusters (k = 10)\n",
        "# Initialize and fit KMeans with k = 10\n",
        "kmeans = # YOUR CODE HERE: Fill this in\n",
        "cluster_labels = # YOUR CODE HERE: Fit and predict cluster labels using X_pca\n",
        "\n",
        "# Get cluster centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Step 5: Visualize the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(10):\n",
        "    plt.scatter(X_pca[cluster_labels == i, 0], X_pca[cluster_labels == i, 1], s=50, label=f'Cluster {i+1}')\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], s=200, c='black', marker='x', label='Centroids')\n",
        "plt.title('Digits Clusters in PCA Space')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# YOUR CODE HERE: Save the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFfg_3U9g63N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}